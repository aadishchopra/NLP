{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadishchopra/NLP/blob/main/TF_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rmpybwysXGV"
      },
      "source": [
        "Following the Tensor Flow guide\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# TensorFlow basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJyZUDbzBTIG"
      },
      "source": [
        "This guide provides a quick overview of _TensorFlow basics_. Each section of this doc is an overview of a larger topicâ€”you can find links to full guides at the end of each section.\n",
        "\n",
        "TensorFlow is an end-to-end platform for machine learning. It supports the following:\n",
        "\n",
        "* Multidimensional-array based numeric computation (similar to <a href=\"https://numpy.org/\" class=\"external\">NumPy</a>.)\n",
        "* GPU and distributed processing\n",
        "* Automatic differentiation\n",
        "* Model construction, training, and export\n",
        "* And more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLegMMvBZYg"
      },
      "source": [
        "## Tensors\n",
        "\n",
        "TensorFlow operates on multidimensional arrays or _tensors_ represented as `tf.Tensor` objects. Here is a two-dimensional tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6ZqX5RnbBS1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0682f0-9e6d-4af6-8e1e-8b5c35f3f3e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]], shape=(2, 3), dtype=int32)\n",
            "(2, 3)\n",
            "<dtype: 'int32'>\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "#notice the dots after the integers. The data type gets changed from float32 to int32\n",
        "x = tf.constant([[1, 2, 3],\n",
        "                 [4, 5, 6]])\n",
        "\n",
        "\n",
        "#help(tf.constant)\n",
        "\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-AOMqevQGN4"
      },
      "source": [
        "The most important attributes of a `tf.Tensor` are its `shape` and `dtype`:\n",
        "\n",
        "* `Tensor.shape`: tells you the size of the tensor along each of its axes.\n",
        "* `Tensor.dtype`: tells you the type of all the elements in the tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUkKeNWZCIJO"
      },
      "source": [
        "TensorFlow implements standard mathematical operations on tensors, as well as many operations specialized for machine learning.\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM7xXNDsBfN5"
      },
      "outputs": [],
      "source": [
        "x + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLGqscTxB61v"
      },
      "outputs": [],
      "source": [
        "5 * x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ImJHd8VfnWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95c5ee0-33f0-4cba-d1ec-7b8204e341f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[14, 32],\n",
              "       [32, 77]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "x @ tf.transpose(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error\n",
        "# x @ x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "cs5h_WVz0dHC",
        "outputId": "2a6c049d-c35d-4eb4-e4fc-02587c4d9f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9114ab99c4fb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7261\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7262\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [2,3], In[1]: [2,3] [Op:MatMul]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9JZD6TYCZWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "182c488b-f992-4ec1-a2e2-43deffb682aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function concat in module tensorflow.python.ops.array_ops:\n",
            "\n",
            "concat(values, axis, name='concat')\n",
            "    Concatenates tensors along one dimension.\n",
            "    \n",
            "    See also `tf.tile`, `tf.stack`, `tf.repeat`.\n",
            "    \n",
            "    Concatenates the list of tensors `values` along dimension `axis`.  If\n",
            "    `values[i].shape = [D0, D1, ... Daxis(i), ...Dn]`, the concatenated\n",
            "    result has shape\n",
            "    \n",
            "        [D0, D1, ... Raxis, ...Dn]\n",
            "    \n",
            "    where\n",
            "    \n",
            "        Raxis = sum(Daxis(i))\n",
            "    \n",
            "    That is, the data from the input tensors is joined along the `axis`\n",
            "    dimension.\n",
            "    \n",
            "    The number of dimensions of the input tensors must match, and all dimensions\n",
            "    except `axis` must be equal.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> t1 = [[1, 2, 3], [4, 5, 6]]\n",
            "    >>> t2 = [[7, 8, 9], [10, 11, 12]]\n",
            "    >>> tf.concat([t1, t2], 0)\n",
            "    <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
            "    array([[ 1,  2,  3],\n",
            "           [ 4,  5,  6],\n",
            "           [ 7,  8,  9],\n",
            "           [10, 11, 12]], dtype=int32)>\n",
            "    \n",
            "    >>> tf.concat([t1, t2], 1)\n",
            "    <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
            "    array([[ 1,  2,  3,  7,  8,  9],\n",
            "           [ 4,  5,  6, 10, 11, 12]], dtype=int32)>\n",
            "    \n",
            "    As in Python, the `axis` could also be negative numbers. Negative `axis`\n",
            "    are interpreted as counting from the end of the rank, i.e.,\n",
            "     `axis + rank(values)`-th dimension.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> t1 = [[[1, 2], [2, 3]], [[4, 4], [5, 3]]]\n",
            "    >>> t2 = [[[7, 4], [8, 4]], [[2, 10], [15, 11]]]\n",
            "    >>> tf.concat([t1, t2], -1)\n",
            "    <tf.Tensor: shape=(2, 2, 4), dtype=int32, numpy=\n",
            "      array([[[ 1,  2,  7,  4],\n",
            "              [ 2,  3,  8,  4]],\n",
            "             [[ 4,  4,  2, 10],\n",
            "              [ 5,  3, 15, 11]]], dtype=int32)>\n",
            "    \n",
            "    Note: If you are concatenating along a new axis consider using stack.\n",
            "    E.g.\n",
            "    \n",
            "    ```python\n",
            "    tf.concat([tf.expand_dims(t, axis) for t in tensors], axis)\n",
            "    ```\n",
            "    \n",
            "    can be rewritten as\n",
            "    \n",
            "    ```python\n",
            "    tf.stack(tensors, axis=axis)\n",
            "    ```\n",
            "    \n",
            "    Args:\n",
            "      values: A list of `Tensor` objects or a single `Tensor`.\n",
            "      axis: 0-D `int32` `Tensor`.  Dimension along which to concatenate. Must be\n",
            "        in the range `[-rank(values), rank(values))`. As in Python, indexing for\n",
            "        axis is 0-based. Positive axis in the rage of `[0, rank(values))` refers\n",
            "        to `axis`-th dimension. And negative axis refers to `axis +\n",
            "        rank(values)`-th dimension.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor` resulting from concatenation of the input tensors.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# like rbind in R\n",
        "\n",
        "tf.concat([x, x, x], axis=0)\n",
        "\n",
        "# axis=1 is for columns\n",
        "tf.concat([x, x, x], axis=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seGBLeD9P_PI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b00c22f-d87c-4391-dd35-e4071e5e1bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function softmax_v2 in module tensorflow.python.ops.nn_ops:\n",
            "\n",
            "softmax_v2(logits, axis=None, name=None)\n",
            "    Computes softmax activations.\n",
            "    \n",
            "    Used for multi-class predictions. The sum of all outputs generated by softmax\n",
            "    is 1.\n",
            "    \n",
            "    This function performs the equivalent of\n",
            "    \n",
            "    ```python\n",
            "    softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis, keepdims=True)\n",
            "    ```\n",
            "    Example usage:\n",
            "    \n",
            "    >>> softmax = tf.nn.softmax([-1, 0., 1.])\n",
            "    >>> softmax\n",
            "    <tf.Tensor: shape=(3,), dtype=float32,\n",
            "    numpy=array([0.09003057, 0.24472848, 0.66524094], dtype=float32)>\n",
            "    >>> sum(softmax)\n",
            "    <tf.Tensor: shape=(), dtype=float32, numpy=1.0>\n",
            "    \n",
            "    Args:\n",
            "      logits: A non-empty `Tensor`. Must be one of the following types: `half`,\n",
            "        `float32`, `float64`.\n",
            "      axis: The dimension softmax would be performed on. The default is -1 which\n",
            "        indicates the last dimension.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor`. Has the same type and shape as `logits`.\n",
            "    \n",
            "    Raises:\n",
            "      InvalidArgumentError: if `logits` is empty or `axis` is beyond the last\n",
            "        dimension of `logits`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Error . \n",
        "x = tf.constant([[1., 2, 3],\n",
        "                 [4, 5, 6]])\n",
        "#softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis, keepdims=True)\n",
        "tf.nn.softmax(x, axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZNZRv1ECjf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5afd911c-fe84-4597-b7a1-5de39c765d6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=21.0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tf.reduce_sum(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNHnIjOVLJfA"
      },
      "source": [
        "Note: Typically, anywhere a TensorFlow function expects a `Tensor` as input, the function will also accept anything that can be converted to a `Tensor` using `tf.convert_to_tensor`. See below for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_XKgjDsL4GE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5819e2e7-4c92-4211-d1fb-2ff02a0e1f6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tf.convert_to_tensor([1,2,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTBt-JUqLJDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f020e9-9f23-429f-a5a3-3c95527856ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=6>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tf.reduce_sum([1,2,3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-mi5031DVxz"
      },
      "source": [
        "Running large calculations on CPU can be slow. When properly configured, TensorFlow can use accelerator hardware like GPUs to execute operations very quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m97Gv5H6Dz0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed30f5c-7174-4abe-c1c1-2cfaf84bbad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow **IS NOT** using the GPU\n"
          ]
        }
      ],
      "source": [
        "if tf.config.list_physical_devices('GPU'):\n",
        "  print(\"TensorFlow **IS** using the GPU\")\n",
        "else:\n",
        "  print(\"TensorFlow **IS NOT** using the GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_PSk_1L2zEY",
        "outputId": "ffb1ba9d-2cc7-4bb4-92b1-7b44634d59dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln2FkLOqMX92"
      },
      "source": [
        "Refer to the [Tensor guide](tensor.ipynb) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVbomvMyEIVF"
      },
      "source": [
        "## Variables\n",
        "\n",
        "# **Normal `tf.Tensor` objects are immutable. To store model weights (or other mutable state) in TensorFlow use a `tf.Variable`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO8_bP4UEzxS"
      },
      "outputs": [],
      "source": [
        "var = tf.Variable([0.0, 0.0, 0.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDLYFvu5FAFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3719a7-ae45-4919-f24e-ca670cd2650c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(3,) dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "var.assign([1, 2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EpiOmxXFDSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb836cb-da03-4cb1-d417-bc8ad08fc86f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(3,) dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "var.assign_add([1, 1, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlvTpi1CMedC"
      },
      "source": [
        "Refer to the [Variables guide](variable.ipynb) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG1Dhv2QFkV3"
      },
      "source": [
        "## Automatic differentiation\n",
        "\n",
        "<a href=\"https://en.wikipedia.org/wiki/Gradient_descent\" class=\"external\">_Gradient descent_</a> and related algorithms are a cornerstone of modern machine learning.\n",
        "\n",
        "To enable this, TensorFlow implements automatic differentiation (autodiff), which uses calculus to compute gradients. Typically you'll use this to calculate the gradient of a model's _error_ or _loss_ with respect to its weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYKOi-z4GY9Y"
      },
      "outputs": [],
      "source": [
        "x = tf.Variable(1.0)\n",
        "\n",
        "def f(x):\n",
        "  y = x**2 + 2*x - 5\n",
        "  return y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=tf.Variable(10.0)\n",
        "def f(x):\n",
        "  y=x**3 + x - 1\n",
        "  return y\n"
      ],
      "metadata": {
        "id": "KMLBXM1F4q4b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozLLop0cHeYl"
      },
      "source": [
        "At `x = 1.0`, `y = f(x) = (1**2 + 2*1 - 5) = -2`.\n",
        "\n",
        "The derivative of `y` is `y' = f'(x) = (2*x + 2) = 4`. TensorFlow can calculate this automatically:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N02NfWpHGvw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db06e13b-d6a4-4a5f-e076-26bda6ce2d34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=301.0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  y = f(x)\n",
        "g_x = tape.gradient(y, x)  # g(x) = dy/dx\n",
        "\n",
        "g_x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2nd order differentiation"
      ],
      "metadata": {
        "id": "d8I90LGHsc1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating my own example with the help of documentation\n",
        "with tf.GradientTape() as tape:\n",
        "  with tf.GradientTape() as tape2:\n",
        "    y=f(x)\n",
        "    g_x=tape.gradient(y, x)  # g(x) = dy/dx\n",
        "g_prime_x=tape2.gradient(g_x, x)  # g(x) = d2y/dx\n",
        "\n",
        "print(\"3x^2+1 = 3*10^2 + 1 is equal to tensor of value 301.0 \",g_x) # 3x^2+1 = 3*10^2 + 1  \n",
        "print(\"6x = 6*10\",g_prime_x)  # 6x = 6*10\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBBsqhEi5Aj1",
        "outputId": "8137c081-f048-4d47-b370-4789400922eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3x^2+1 = 3*10^2 + 1 is equal to tensor of value 301.0  tf.Tensor(301.0, shape=(), dtype=float32)\n",
            "6x = 6*10 tf.Tensor(60.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-DVYJfcIRPd"
      },
      "source": [
        "This simplified example only takes the derivative with respect to a single scalar (`x`), but TensorFlow can compute the gradient with respect to any number of non-scalar tensors simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECK3I9bUMk_r"
      },
      "source": [
        "Refer to the [Autodiff guide](autodiff.ipynb) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VglUM4M3KhNz"
      },
      "source": [
        "## Graphs and tf.function\n",
        "\n",
        "While you can use TensorFlow interactively like any Python library, TensorFlow also provides tools for:\n",
        "\n",
        "* **Performance optimization**: to speed up training and inference.\n",
        "* **Export**: so you can save your model when it's done training.\n",
        "\n",
        "These require that you use `tf.function` to separate your pure-TensorFlow code from Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VitACyZWKJD_"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def my_func(x):\n",
        "  print('Tracing.\\n')\n",
        "  return tf.reduce_sum(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBYDh-huNUBZ"
      },
      "source": [
        "The first time you run the `tf.function`, although it executes in Python, it captures a complete, optimized graph representing the TensorFlow computations done within the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vkOFSEkoM1bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5aca73-d3b4-41f9-a18a-e5dd831299a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#Although in the example the first example used has a dtype of int32. I used float32 to show that once the data\n",
        "#type is converted to float32 tf does not revert back to a new tf graph. And therefor in none of the examples\n",
        "# \"tracing\" is print\n",
        "x = tf.constant([1.0, 2.0, 3.0])\n",
        "my_func(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3aWzt-rNsBa"
      },
      "source": [
        "On subsequent calls TensorFlow only executes the optimized graph, skipping any non-TensorFlow steps. Below, note that `my_func` doesn't print _tracing_ since `print` is a Python function, not a TensorFlow function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "23dMHWwwNIoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd33e8b-9dbb-40ab-aab1-a973a9e89808"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=27>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "x = tf.constant([10, 9, 8])\n",
        "my_func(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSeTti6zki0n"
      },
      "source": [
        "A graph may not be reusable for inputs with a different _signature_ (`shape` and `dtype`), so a new graph is generated instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OWffqyhqlVPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef58efe-c32f-4976-8d8f-ec964d32a598"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=27.3>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "x = tf.constant([10.0, 9.1, 8.2], dtype=tf.float32)\n",
        "my_func(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWknAA_zNTOa"
      },
      "source": [
        "These captured graphs provide two benefits:\n",
        "\n",
        "* In many cases they provide a significant speedup in execution (though not this trivial example).\n",
        "* You can export these graphs, using `tf.saved_model`, to run on other systems like a [server](https://www.tensorflow.org/tfx/serving/docker) or a [mobile device](https://www.tensorflow.org/lite/guide), no Python installation required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLUJ6f2eMsA8"
      },
      "source": [
        "Refer to [Intro to graphs](intro_to_graphs.ipynb) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_36xPDPPBqp"
      },
      "source": [
        "## Modules, layers, and models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDaT7kCpUgnJ"
      },
      "source": [
        "`tf.Module` is a class for managing your `tf.Variable` objects, and the `tf.function` objects that operate on them. The `tf.Module` class is necessary to support two significant features:\n",
        "\n",
        "1. You can save and restore the values of your variables using `tf.train.Checkpoint`. This is useful during training as it is quick to save and restore a model's state.\n",
        "2. You can import and export the `tf.Variable` values _and_ the `tf.function` graphs using `tf.saved_model`. This allows you to run your model independently of the Python program that created it.\n",
        "\n",
        "Here is a complete example exporting a simple `tf.Module` object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1MqEcZOqPBDV"
      },
      "outputs": [],
      "source": [
        "class MyModule(tf.Module):\n",
        "  def __init__(self, weights):\n",
        "    self.weight = tf.Variable(weights)\n",
        "\n",
        "  @tf.function\n",
        "  def activation(self, inputs,bias):\n",
        "    print('tracing')\n",
        "    return inputs * self.weight + bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "la2G82HfVfU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c5e598-8479-45e7-a190-9eb048d8153d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tracing\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 4,  7, 10], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "mod = MyModule(weights=3)\n",
        "mod.activation(inputs = tf.constant([1, 2, 3]),bias=tf.constant(1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can verify that it didn't print tracing. \n",
        "mod.activation(inputs = tf.constant([5, 2, 3]),bias=tf.constant(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTRPcklMx_gF",
        "outputId": "e99da1ca-185c-40d3-d9aa-60bc0b930d17"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([16,  7, 10], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "1MlfbEMjVzG4"
      },
      "outputs": [],
      "source": [
        "save_path = './saved'\n",
        "tf.saved_model.save(mod, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  >>> class Dense(tf.Module):\n",
        "  ...   def __init__(self, input_dim, output_size, name=None):\n",
        "  ...     super().__init__(name=name)\n",
        "  ...     self.w = tf.Variable(\n",
        "  ...       tf.random.normal([input_dim, output_size]), name='w')\n",
        "  ...     self.b = tf.Variable(tf.zeros([output_size]), name='b')\n",
        "  ...   def __call__(self, x):\n",
        "  ...     y = tf.matmul(x, self.w) + self.b\n",
        "  ...     return tf.nn.relu(y)"
      ],
      "metadata": {
        "id": "mY2jrD7SwxJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaSJX7zQXCm4"
      },
      "source": [
        "Save the `Module`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgfoftD4XGJW"
      },
      "source": [
        "The resulting SavedModel is independent of the code that created it. You can load a SavedModel from Python, other language bindings, or [TensorFlow Serving](https://www.tensorflow.org/tfx/serving/docker). You can also convert it to run with [TensorFlow Lite](https://www.tensorflow.org/lite/guide) or [TensorFlow JS](https://www.tensorflow.org/js/guide)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "pWuLOIKBWZYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf28f16-7733-4006-cdd3-dd08b2f78968"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 5,  8, 11], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "reloaded = tf.saved_model.load(save_path)\n",
        "type(reloaded) # Loads the object\n",
        "reloaded.activation(tf.constant([1, 2, 3]),bias=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxU6P1RGwHyC"
      },
      "source": [
        "The `tf.keras.layers.Layer` and `tf.keras.Model` classes build on `tf.Module` providing additional functionality and convenience methods for building, training, and saving models. Some of these are demonstrated in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQzt3yaWMzLf"
      },
      "source": [
        "Refer to [Intro to modules](intro_to_modules.ipynb) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk1IEG5aav7X"
      },
      "source": [
        "## Training loops\n",
        "\n",
        "Now put this all together to build a basic model and train it from scratch.\n",
        "\n",
        "First, create some example data. This generates a cloud of points that loosely follows a quadratic curve:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcuFr7KPRPzn"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "matplotlib.rcParams['figure.figsize'] = [9, 6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXN9E_xf-GiP"
      },
      "outputs": [],
      "source": [
        "x = tf.linspace(-2, 2, 201)\n",
        "x = tf.cast(x, tf.float32)\n",
        "\n",
        "def f(x):\n",
        "  y = x**2 + 2*x - 5\n",
        "  return y\n",
        "\n",
        "y = f(x) + tf.random.normal(shape=[201])\n",
        "\n",
        "plt.plot(x.numpy(), y.numpy(), '.', label='Data')\n",
        "plt.plot(x, f(x), label='Ground truth')\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De5LldboSWcW"
      },
      "source": [
        "Create a quadratic model with randomly initialized weights and a bias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pypd0GB4SRhf"
      },
      "outputs": [],
      "source": [
        "class Model(tf.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    # Randomly generate weight and bias terms\n",
        "    rand_init = tf.random.uniform(shape=[3], minval=0., maxval=5., seed=22)\n",
        "    # Initialize model parameters\n",
        "    self.w_q = tf.Variable(rand_init[0])\n",
        "    self.w_l = tf.Variable(rand_init[1])\n",
        "    self.b = tf.Variable(rand_init[2])\n",
        "  \n",
        "  @tf.function\n",
        "  def __call__(self, x):\n",
        "    # Quadratic Model : quadratic_weight * x^2 + linear_weight * x + bias\n",
        "    return self.w_q * (x**2) + self.w_l * x + self.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36o7VjaesScg"
      },
      "source": [
        "First, observe your model's performance before training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkwToC5BWV1c"
      },
      "outputs": [],
      "source": [
        "quad_model = Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReWhH40wTY5F"
      },
      "outputs": [],
      "source": [
        "def plot_preds(x, y, f, model, title):\n",
        "  plt.figure()\n",
        "  plt.plot(x, y, '.', label='Data')\n",
        "  plt.plot(x, f(x), label='Ground truth')\n",
        "  plt.plot(x, model(x), label='Predictions')\n",
        "  plt.title(title)\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0JtXQat-nlk"
      },
      "outputs": [],
      "source": [
        "plot_preds(x, y, f, quad_model, 'Before training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLzwD0-ascGf"
      },
      "source": [
        "Now, define a loss for your model:\n",
        "\n",
        "Given that this model is intended to predict continuous values, the mean squared error (MSE) is a good choice for the loss function. Given a vector of predictions, $\\hat{y}$, and a vector of true targets, $y$, the MSE is defined as the mean of the squared differences between the predicted values and the ground truth.\n",
        "\n",
        "$MSE = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{y}_i -y_i)^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCtJ1uuCseZd"
      },
      "outputs": [],
      "source": [
        "def mse_loss(y_pred, y):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EWyDu3zot2w"
      },
      "source": [
        "Write a basic training loop for the model. The loop will make use of the MSE loss function and its gradients with respect to the input in order to iteratively update the model's parameters. Using mini-batches for training provides both memory efficienciy and faster convergence. The `tf.data.Dataset` API has useful functions for batching and shuffling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kX_-zily2Ia"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "dataset = dataset.shuffle(buffer_size=x.shape[0]).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOaES5gyTDtG"
      },
      "outputs": [],
      "source": [
        "# Set training parameters\n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "losses = []\n",
        "\n",
        "# Format training loop\n",
        "for epoch in range(epochs):\n",
        "  for x_batch, y_batch in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      batch_loss = mse_loss(quad_model(x_batch), y_batch)\n",
        "    # Update parameters with respect to the gradient calculations\n",
        "    grads = tape.gradient(batch_loss, quad_model.variables)\n",
        "    for g,v in zip(grads, quad_model.variables):\n",
        "        v.assign_sub(learning_rate*g)\n",
        "  # Keep track of model loss per epoch\n",
        "  loss = mse_loss(quad_model(x), y)\n",
        "  losses.append(loss)\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Mean squared error for step {epoch}: {loss.numpy():0.3f}')\n",
        "\n",
        "# Plot model results\n",
        "print(\"\\n\")\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
        "plt.title('MSE loss vs training iterations');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW5B2TTRsvxE"
      },
      "source": [
        "Now, observe your model's performance after training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qcvzyg3eYLh8"
      },
      "outputs": [],
      "source": [
        "plot_preds(x, y, f, quad_model, 'After training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbtmFJIXb6qm"
      },
      "source": [
        "That's working, but remember that implementations of common training utilities are available in the `tf.keras` module. So, consider using those before writing your own. To start with, the `Model.compile` and `Model.fit` methods implement a training loop for you:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjx23MiztFmT"
      },
      "source": [
        "Begin by creating a Sequential Model in Keras using `tf.keras.Sequential`. One of the simplest Keras layers is the dense layer, which can be instantiated with `tf.keras.layers.Dense`. The dense layer is able to learn multidimensional linear relationships of the form $\\mathrm{Y} = \\mathrm{W}\\mathrm{X} +  \\vec{b}$. In order to learn a nonlinear equation of the form, $w_1x^2 + w_2x + b$, the dense layer's input should be a data matrix with $x^2$ and $x$ as features. The lambda layer, `tf.keras.layers.Lambda`, can be used to perform this stacking transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rt8HP2TZhEM"
      },
      "outputs": [],
      "source": [
        "new_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Lambda(lambda x: tf.stack([x, x**2], axis=1)),\n",
        "    tf.keras.layers.Dense(units=1, kernel_initializer=tf.random.normal)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73kCo1BtP3rQ"
      },
      "outputs": [],
      "source": [
        "new_model.compile(\n",
        "    loss=tf.keras.losses.MSE,\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01))\n",
        "\n",
        "history = new_model.fit(x, y,\n",
        "                        epochs=100,\n",
        "                        batch_size=32,\n",
        "                        verbose=0)\n",
        "\n",
        "new_model.save('./my_new_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3q5d1SzvzTq"
      },
      "source": [
        "Observe your Keras model's performance after training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo7zRV7XZjv7"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.ylabel('Loss [Mean Squared Error]')\n",
        "plt.title('Keras training progress');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB44a9YsvnfK"
      },
      "outputs": [],
      "source": [
        "plot_preds(x, y, f, new_model, 'After Training: Keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng-BY_eGS0bn"
      },
      "source": [
        "Refer to [Basic training loops](basic_training_loops.ipynb) and the [Keras guide](https://www.tensorflow.org/guide/keras) for more details."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}